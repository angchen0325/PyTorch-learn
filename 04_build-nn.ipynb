{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src=\"data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iMjU2cHgiIGhlaWdodD0iMzEwcHgiIHZpZXdCb3g9IjAgMCAyNTYgMzEwIiB2ZXJzaW9uPSIxLjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPgogICAgPHRpdGxlPlB5VG9yY2g8L3RpdGxlPgogICAgPGc+CiAgICAgICAgPHBhdGggZD0iTTEyNy44MjUzNzUsMCBMMTI3LjgyNTM3NSw0NS4wNTMyMDYgTDU4LjYwMTQzODUsMTE0LjI3NDU4MSBDMjIuMzcyNDQ5OCwxNTEuMDE5Mjc5IDIyLjM3NjE0NjYsMjEwLjEyNzU5NCA1OC42MTI1MjksMjQ3LjUzODc3MiBMNTkuNzIxNjkxNywyNDguNjY1NzU3IEM5Ni43NDIxNTU1LDI4Ni4zODQ3MiAxNTcuNTExNTk2LDI4Ni4zODQ3MiAxOTUuMjMwNTU5LDI0OC42NjU3NTcgQzIzMi41NzIzMzMsMjEyLjAxNTQ5OCAyMzIuOTQ1NzUxLDE1Mi4wODg4NjcgMTk2LjM1MDgxMywxMTQuMjk1MzI3IEwxOTUuMjMwNTU5LDExMy4xNTY4ODkgTDIxOC4yODEwMzcsOTAuMTA2NDEyIEMyNjguNTcyOTg4LDE0MC4zOTgzNjMgMjY4LjU3Mjk4OCwyMjEuMDc1MDM0IDIxOC4yODEwMzcsMjcxLjcxNjIzNSBDMTY5LjAzNjgzNSwzMjIuMDA4MTg2IDg4LjAxMDkxNDEsMzIyLjAwODE4NiAzNy43MTg5NjMyLDI3MS43MTYyMzUgQy0xMi4wNzAwNjgyLDIyMS45MjcyMDMgLTEyLjU2Nzk1ODUsMTQyLjAxNTgwOCAzNi4yMjUyOTIyLDkxLjYyNDMyOTMgTDM3LjcxODk2MzIsOTAuMTA2NDEyIEwxMjcuODI1Mzc1LDAgWiBNMTczLjIyNzgzMSw1MC45OTA0NTAyIEMxODIuNDg2MzIzLDUwLjk5MDQ1MDIgMTg5Ljk5MTgxNCw1OC40OTU5NDEzIDE4OS45OTE4MTQsNjcuNzU0NDMzOCBDMTg5Ljk5MTgxNCw3Ny4wMTI5MjYzIDE4Mi40ODYzMjMsODQuNTE4NDE3NSAxNzMuMjI3ODMxLDg0LjUxODQxNzUgQzE2My45NjkzMzgsODQuNTE4NDE3NSAxNTYuNDYzODQ3LDc3LjAxMjkyNjMgMTU2LjQ2Mzg0Nyw2Ny43NTQ0MzM4IEMxNTYuNDYzODQ3LDU4LjQ5NTk0MTMgMTYzLjk2OTMzOCw1MC45OTA0NTAyIDE3My4yMjc4MzEsNTAuOTkwNDUwMiBaIiBmaWxsPSIjRUU0QzJDIj48L3BhdGg+CiAgICA8L2c+Cjwvc3ZnPgo=\" style=\"width:6.5%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=5 face=\"Helvetica\" color=#EE4B2B><b>\n",
    "Pytorch Tutorial: Build the Neural Network\n",
    "</b></font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font face=\"Helvetica\" size=3><b>Ang Chen</b></font></center>\n",
    "<center><font face=\"Helvetica\" size=3>July, 2024</font></center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks comprise of layers/modules that perform operations on data.\n",
    "The $\\texttt{torch.nn}$ namespace provides all the building blocks you need to build your neural neetwork.\n",
    "Every module in PyTorch subclasses the $\\mathtt{nn.Module}$.\n",
    "A neural network is a module itself that consists of other modules (layers).\n",
    "This nested structure allows for building and managing complex architectures easily.\n",
    "\n",
    "In the fowllowing sections, we will build a neural network to classify images in the FashionMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Device for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to be able to train our model on a hardware accelerator like the GPU or MPS, if available.\n",
    "Let's check to see if $\\texttt{torch.cuda}$ or $\\texttt{torch.backend.mps}$ are available, otherwise we use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our neural network by subclassing $\\texttt{nn.Module}$, and initialize the neural network layers in $\\texttt{\\_\\_init\\_\\_}$.\n",
    "Every $\\texttt{nn.Module}$ subclass implements the operations on input data in the $\\texttt{forward}$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "        nn.Linear(28*28, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of $\\texttt{NeuralNetwork}$, and move it to the $\\texttt{device}$, and print its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model. we pass it the input data.\n",
    "This executes the model's $\\texttt{forward}$, along with some background operations.\n",
    "Do not call $\\texttt{model.forward()}$ directly.\n",
    "\n",
    "Calling the model on the imput returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output.\n",
    "We get the prediction probabilities by passing it through an instantce of $\\texttt{nn.Softmax}$ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([2], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the layers in the FashionMNIST model.\n",
    "To illustrate it, we will take a sample minibatch of 3 images of size 28x28 \n",
    "and see what happens to it as we pass it through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "input_image.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the $\\texttt{nn.Flatten}$ layer to convert each 2D 28$\\times$28 image into a contiguous array of 784 pixel values (the minibatch dimension (at dim=0) is maintained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "flat_image.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear layer is a module that applies a linear transformation on the input using its stored weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "hidden1.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear activations are what create the complex mapping between the model's inputs and outputs.\n",
    "They are apllied after linear transformations to introduc nonlinearity,\n",
    "helping neural neetworks learn a wide variety of phenomena.\n",
    "\n",
    "In this model, we use $\\texttt{nn.ReLU}$ bewtween our linear layers, but there's other activatoins to introduce non-linearity in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-4.2737e-01, -4.9111e-01,  3.4963e-01,  5.6632e-01,  2.2415e-01,\n",
      "          1.1379e-01,  9.7172e-03,  3.8196e-01,  4.2302e-02,  3.1843e-01,\n",
      "         -1.2421e-01, -8.9374e-01, -1.8459e-02, -1.9446e-01,  1.5748e-02,\n",
      "          7.8721e-04, -1.5392e-01, -3.9268e-02,  9.2933e-02, -2.1698e-01],\n",
      "        [-1.9865e-01, -2.2511e-01,  8.4534e-02,  3.6073e-01,  2.9812e-01,\n",
      "         -1.4895e-01, -3.8197e-02,  2.5157e-01, -9.6405e-04,  2.0031e-01,\n",
      "         -2.1452e-01, -5.9686e-01, -1.9009e-01, -2.4979e-01, -4.1683e-01,\n",
      "         -3.5008e-01, -6.3378e-03,  3.0951e-01, -1.1961e-03, -1.2958e-01],\n",
      "        [-2.6814e-01, -4.6044e-01,  2.1683e-01,  3.7727e-01, -6.6986e-02,\n",
      "          6.2326e-02,  7.0886e-03,  2.7343e-01,  2.9366e-01,  7.0789e-02,\n",
      "         -4.0734e-01, -6.9680e-01, -3.6037e-01, -1.7712e-01, -5.1263e-01,\n",
      "         -1.9949e-01, -1.2035e-01,  7.8629e-02, -2.4945e-01, -1.6903e-01]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.3496, 0.5663, 0.2241, 0.1138, 0.0097, 0.3820, 0.0423,\n",
      "         0.3184, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.0008, 0.0000, 0.0000,\n",
      "         0.0929, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0845, 0.3607, 0.2981, 0.0000, 0.0000, 0.2516, 0.0000,\n",
      "         0.2003, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3095,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2168, 0.3773, 0.0000, 0.0623, 0.0071, 0.2734, 0.2937,\n",
      "         0.0708, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0786,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\texttt{nn.Sequential}$ is an ordered container of modules. \n",
    "The data is passed through all the modules in the same order as defined. \n",
    "You can use sequential containers to put together a quick network like $\\texttt{seq\\_modules}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0651, -0.0931,  0.1512,  0.1764, -0.0966,  0.0848, -0.0235,  0.1350,\n",
       "         -0.1150, -0.1079],\n",
       "        [-0.0262, -0.1801,  0.0466,  0.0065, -0.0154,  0.1601, -0.0083,  0.0682,\n",
       "         -0.2406,  0.0362],\n",
       "        [ 0.0985, -0.0745,  0.0929,  0.1635, -0.1037,  0.0705,  0.0041,  0.0300,\n",
       "         -0.0307, -0.1618]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last linear layer of the neural network returns logits - raw values in [-infty, infty] - which are passed to the nn.Softmax module. \n",
    "The logits are scaled to values [0, 1] representing the model's predicted probabilities for each class.\n",
    "$\\texttt{dim}$ parameter indicates the dimension along which the values must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1042, 0.0890, 0.1136, 0.1165, 0.0887, 0.1063, 0.0954, 0.1118, 0.0870,\n",
       "         0.0877],\n",
       "        [0.0983, 0.0843, 0.1057, 0.1016, 0.0994, 0.1185, 0.1001, 0.1081, 0.0794,\n",
       "         0.1047],\n",
       "        [0.1089, 0.0916, 0.1083, 0.1162, 0.0889, 0.1059, 0.0991, 0.1017, 0.0957,\n",
       "         0.0839]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pred_probab[2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many layers inside a neural network are *parameterized*, i.e. have associated weights and biases that are optimized during training.\n",
    "Subclassing nn.Module automatically tracks all fields defined inside your model object, and makes all parameters accessible using your model's $\\texttt{parameters()}$ or $\\texttt{named\\_parameters()}$ methods.\n",
    "\n",
    "In this example, we iterate over each parameter, and print its size and a preview of its values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0315, -0.0311,  0.0135,  ...,  0.0152, -0.0211, -0.0012],\n",
      "        [-0.0018, -0.0058, -0.0242,  ..., -0.0053,  0.0262, -0.0304]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([ 0.0096, -0.0253], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0414, -0.0326,  0.0441,  ...,  0.0087,  0.0306, -0.0407],\n",
      "        [-0.0062, -0.0224,  0.0008,  ..., -0.0162, -0.0333,  0.0048]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0033,  0.0218], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0229, -0.0224, -0.0247,  ..., -0.0337, -0.0235, -0.0101],\n",
      "        [-0.0202, -0.0058, -0.0066,  ...,  0.0329, -0.0223, -0.0311]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0227, -0.0308], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
